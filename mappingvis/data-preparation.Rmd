---
title: "Data Preparation"
description: |
  Generating data for model training.
author:
  - name: Kris Sankaran
    affiliation: UW Madison
date: "`r Sys.Date()`"
output: distill::distill_article
params:
  raw_dir: "/Users/kris/data/raw"
  out_dir: "/Users/kris/data/processed/train/"
  basins: "https://uwmadison.box.com/shared/static/2ptmi9b4gt5d5vyusju5u8kn5n1s6hnd.csv"
  #basins: "https://uwmadison.box.com/shared/static/iilcsf3bbois8tmt7pklriu219s4wlu6.csv" # for test basins
  n_patches: 70
---

1. In these notes, we generate and visualize patches of data that will be used
to train the mapping model. This is necessary for a few different reasons,

* Preprocessing: The different channels need to be normalized, since they have
such different ranges. There are also a few channels that we should drop, like
the `BQA` quality channel we saw earlier.
* Imbalance: The glaciers only make up a relatively fraction of the total area
that we have imagery for. Our model can be trained more efficiently by zooming
into the parts of the region that actually have glaciers.
* Image size: Even if we completed these preprocessing steps, each satellite
image is much larger than anything a machine learning algorithm could work with.
We'll need to break the processed imagery into pieces that can be sequentially
streamed in for training the model^[For reference, the famous MNIST example ]


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r}
library("abind")
library("dplyr")
library("gdalUtils")
library("RStoolbox")
library("ggplot2")
library("purrr")
library("raster")
library("readr")
library("reticulate")
library("sf")
library("stringr")
library("tidyr")
use_condaenv("notebook")
np <- import("numpy")
source("data.R")
theme_set(theme_bw())
set.seed(123)
```

```{r}
y_path <- file.path(params$raw_dir, "glaciers.geojson")
basins <- read_csv(params$basins)

y <- read_sf(y_path) %>%
  filter(Sub_basin %in% basins$Sub_basin)
```

```{r}
centers <- y %>%
  st_sample(params$n_patches, type = "random", by_polygon = FALSE) %>%
  st_coordinates()
colnames(centers) <- c("Longitude", "Latitude")
```

```{r}
p <- ggplot(y, aes(x = Longitude, y = Latitude)) +
  geom_sf(data = y, aes(fill = Glaciers)) +
  geom_point(data = as.data.frame(centers), col = "red", size = 2) +
  scale_fill_manual(values = c("#93b9c3", "#4e326a"))

p
```

```{r}
p + coord_sf(xlim = c(70.7, 71.2),  ylim = c(36.2, 36.5))
```

```{r}
vrt_path <- file.path(params$raw_dir, "region.vrt")
ys <- y %>% split(.$Glaciers)
patch <- generate_patch(vrt_path, centers[1, ])
patch_y <- label_mask(ys, patch$raster)
```

```{r}
ggRGB(brick(patch$x), r = 5, g = 4, b = 2)
ggRGB(brick(patch$x), r = 13, g = 13, b = 13)
ggRGB(brick(patch_y), r = NULL)
```

```{r}
# same code as before, for making a histogram
sample_ix <- sample(nrow(patch$x), 250)
x_df <- patch$x[sample_ix, sample_ix, ] %>%
  brick() %>%
  as.data.frame() %>%
  pivot_longer(cols = everything())
```


```{r}
ggplot(x_df) +
  geom_histogram(aes(x = value)) +
  facet_wrap(~ name, scale = "free_x")
```

```{r}
#write_patches(vrt_path, ys, centers, params$out_dir)
```
